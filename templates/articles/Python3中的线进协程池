{% extends 'layout.html' %}
<title>Python3中的线进协程池</title>

{% block link %}
<link rel="stylesheet" style="text/css" href={{ url_for("static", filename="bear.css") }}>
<link rel="stylesheet" style="text/css" href={{ url_for("static", filename="style.css") }}>
<script src={{ url_for("static", filename="jquery-3.2.1.min.js") }}></script>
<script src={{ url_for("static", filename="bear.js") }}></script>
{% endblock %}
    {% block header %}

<meta name="created" content="2017-08-30 08:46:45">
<meta name="tags" content="Python, 技术">

{% endblock %}
{% block body %}
                  <div class="note-wrapper">
<h1>Python3中的线进协程池</h1>
<p><span class="hashtag">#技术</span></p>
<p><span class="hashtag">#Python</span></p>
<br/>
<div class="desc">
在之前的应用开发的场景中，为了增加程序的运行效率我会用到多线程或者多进程。思路有两种
</div>
在给了一个task列表的前提下
<ol start="1">
    <li>给其中的每个task都开个线程跑task。</li>
    <li>指定线程数比如40然后就开40个线程。 把所有的任务放到一个Queue里面去，然后再用queue.qsize(), queue.get()来判断获取外层还要加多个try catch来应对多线程的变化</li>
    </ol>
<br/>
<p>以上两种情况 第一种写起来比较简单 但是有成千上万个任务的时候就没办法控制线程的数量 也就是不适用于高并发。 第二种写起来比较麻烦而且传参数更麻烦我的天。 </p>
<p>今天看到了dos_attck.py里面用了线程池和进程池 我就来研究了一下 发现卧槽！ 这玩意儿对上面👆两种情况进行了合并 取其精华去其糟粕 可以说爽！</p>
<br/>
<p>第一步 安装threadpool模块</p>
<blockquote>
<p>pip install threadpool</p>
</blockquote>
<p>第二步 写代码</p>
<pre><code class="code-multiline">from threadpool import ThreadPool
from threadpool import makeRequests
pool = ThreadPool(poolsize)  # 指定pool的大小 也就是线程数
requests = makeRequests(some_callable, list_of_args, callback)
[pool.putRequest(req) for req in requests]  # 用了行列式简化
pool.wait()  # 相当于 thread.join()</code></pre>
<p><br/></p>
<p><mark>注意</mark>  makeRequests(some_callable, list_of_args, callback) </p>
<p>第一个参数是 目标函数。 </p>
<p>第二个对象是 N个参数 可以小于poolsize。 如果大于poolsize他就会自动分配， 如果目标参数有多个list_of_args = [((1, 2, 3), {}), ((1, 2, 3), {})] 这样的形式</p>
<p>第三个参数是 callback。 接受两个参数 一个参数是返回值 第二个参数是<workrequest args="['dd']" exception="False" id="4505401664" kwargs="{}"></workrequest></p>
<br/>
<br/>
<p><b>总结</b></p>
<p>更方便 更直观 代码更少</p>
<br/>
<hr/>
<br/>
<h1>进程池(multiprocessing)</h1>
<p>物以类聚 其实都是差不多的概念</p>
<p>multiprocessing模块是python自带 不需要安装</p>
<pre><code class="code-multiline">import multiprocessing
def func(msg):
    print(msg)
    return "func"

pool = multiprocessing.Pool(processes=3)
for i in range(4):
    msg = "hello %d" % i
    pool.apply_async(func, (msg, ))
pool.close()
pool.join()  # 调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool, join函数等待所有子进程结束</code></pre>
<p><br/></p>
<br/>
<h1>协程池</h1>
<p>把这三个玩意儿放一起了。 上网搜好像是没有这个什么所谓的协程池的。 反正原理都一样那我就自己编一个。 主要是看了K神的grequests模块儿 里面就有用到这个pool的概念 我就把他单独提出来记录记录。 至于不懂什么是协程的小朋友可以回去补补，保证你用了他以后不会想用多线程了。</p>
<p><b>Pools are useful because you can specify size and can hence limit concurrency</b></p>
<br/>
<blockquote>
<p>pip install grequests</p>
</blockquote>
<pre><code class="code-multiline">import gevent
from gevent import monkey
from gevent.pool import Pool
monkey.patch_all(thread=False, select=False)
pool = gevent.Pool(size)

def func(param):
    print(param)
    return "func"

rs = [pool.spawn(func, "hello") for _ in range(4)]
gevent.joinall(tasks)

</code></pre>
</div>
{% endblock %}
